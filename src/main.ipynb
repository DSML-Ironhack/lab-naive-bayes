{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca411179-237e-4f6a-853c-3db4bae77d7c",
   "metadata": {},
   "source": [
    "# Predicting Diabetes Using Naive Bayes\n",
    "\n",
    "### Objective\n",
    "- Apply Naive Bayes for binary classification.\n",
    "- Practice data exploration and preprocessing.\n",
    "- Evaluate model performance using appropriate metrics.\n",
    "- Understand and interpret the log probabilities used in Naive Bayes.\n",
    "\n",
    "### Dataset\n",
    "This lab uses the Pima Indians Diabetes Dataset from the UCI Machine Learning Repository. It contains 8 features based on medical information, with a binary target indicating the presence of diabetes (1) or absence (0).\n",
    "\n",
    "### Features\n",
    "`Pregnancies`: Number of times pregnant\n",
    "`Glucose`: Plasma glucose concentration\n",
    "`BloodPressure`: Diastolic blood pressure (mm Hg)\n",
    "`SkinThickness`: Triceps skinfold thickness (mm)\n",
    "`Insulin`: 2-Hour serum insulin (mu U/ml)\n",
    "`BMI`: Body mass index (weight in kg/(height in m)^2)\n",
    "`DiabetesPedigreeFunction`: Diabetes pedigree function (a function based on family history)\n",
    "`Age`: Age (years)\n",
    "`Outcome`: Class variable (1 if patient has diabetes, 0 otherwise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69ab905-df5a-4814-b608-85e0b9ce4522",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63f66cf-2fc1-4232-af50-527235c37374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries for data manipulation, model training, and evaluation.\n",
    "# your code here\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8795d9-448e-442e-8825-2544731f44df",
   "metadata": {},
   "source": [
    "### Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0540e43-06d2-4b2d-a36c-2ccc6ce47286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Pima Indiands Diabetes Dataset in the folder ../data and preview the data\n",
    "# Display summary statistics\n",
    "# your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dceacc95-5238-46dd-bbe2-304cfce94133",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "\n",
    "1. *Handling Missing Values*: Replace 0 values in Glucose, BloodPressure, SkinThickness, Insulin, and BMI columns with their respective median values.\n",
    "2. *Split Data*: Separate the feature columns (X) and target (y), and then split into training and test sets with an 80-20 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7320c1cf-09b0-47ac-bd6a-3a3955e89f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4e4bcc-7f24-4b93-9975-ec9f436c8c73",
   "metadata": {},
   "source": [
    "### Train a Naïve Bayes Classifier\n",
    "\n",
    "Since the features are continuous, we need to use the `GaussianNB` model instead of the ones we used so far for categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b94c06c-42c7-48e9-a82f-3087041deb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a519ee-88e5-47ec-8dc2-21c1483ba242",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "Evaluate the model's accuracy, precision and recall. Analyse the confusion matrix.\n",
    "Give the setting of the problem, which metrics would you privilege?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3a26af-011b-4f6f-9e34-cfdf185cd2c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d028fb89-4f57-4f8d-a714-f369ab0b5911",
   "metadata": {},
   "source": [
    "### Exploring Log Probabilities in Naïve Bayes\n",
    "\n",
    "Naive Bayes calculates log probabilities (logprobs) for each class to make predictions. Let's use `predict_log_proba` to calculate the log probabilities for each class (diabetes vs. no diabetes) for a few samples in the test set.\n",
    "\n",
    "Question: For a given instance in the test set, calculate the log probabilities for each class (diabetes vs. no diabetes) and interpret the values. How does Naive Bayes decide the predicted class based on these log probabilities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3478981e-3183-4ba3-8226-f27b7d86639e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a few samples from the test set\n",
    "sample_indices = [0, 1, 12]  # Change these indices as desired\n",
    "X_sample = X_test.iloc[sample_indices]\n",
    "\n",
    "# Calculate log probabilities for each class\n",
    "log_probs = nb_classifier.predict_log_proba(X_sample)\n",
    "\n",
    "# Display results\n",
    "for i, index in enumerate(sample_indices):\n",
    "    print(f\"Sample {index} - Log Probabilities:\")\n",
    "    print(f\"No Diabetes (0): {log_probs[i][0]:.4f}, Diabetes (1): {log_probs[i][1]:.4f}\")\n",
    "    print(f\"Predicted Class: {nb_classifier.predict(X_sample.iloc[[i]])[0]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929a2b08-fa53-4edd-81e3-347351cc7fcb",
   "metadata": {},
   "source": [
    "- Interpretation of Log Probabilities: Log probabilities represent the logarithm of the probability for each class. A higher log probability (closer to zero, since log values are negative) indicates a higher likelihood for that class.\n",
    "- Decision-Making: The model predicts the class with the highest log probability. If the log probability for Diabetes (1) is higher (closer to zero) than for No Diabetes (0), the model will predict Diabetes (1).\n",
    "\n",
    "Convert log probabilities back to regular probabilities using np.exp(log_probs) to see how log transformations aid computation without changing predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebdc252-3f81-4c6e-801c-addcad261528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# Convert log probabilities back to regular probabilities using np.exp(log_probs) to see how log transformations aid computation without changing predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ba72a4-28b9-46ce-954d-4a58f31f2c2e",
   "metadata": {},
   "source": [
    "Change your decision treshold so that either class 1 or 0 becomes more frequent in order to optimize your preferred metric (precision or recall) for this problem. Try multiple tresholds until you are satisfied with your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a633a9d1-52f5-456a-a696-338bfbfe6d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "treshold = 0.5 # adjust this number to make it easier/harder to classify someone as diabetic\n",
    "\n",
    "\n",
    "# Calculate log probabilities for each class\n",
    "log_probs = nb_classifier.predict_log_proba(X_test)\n",
    "\n",
    "#compute probability of No Diabetes (0) vs Diabetes (1)\n",
    "probabilities = []\n",
    "for i, index in enumerate(X_test.index):\n",
    "    prediction = 0 if np.exp(log_probs[i][0]) >= treshold else 1\n",
    "    probabilities.append({'index':index,'no_diab_prob': np.exp(log_probs[i][0]), 'diab_prob': np.exp(log_probs[i][0]), 'prediction':prediction})\n",
    "\n",
    "probabilities = pd.DataFrame(probabilities)\n",
    "probabilities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e08d565-3d2c-4420-a9d8-9b166d6f3285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the confusion matrix for the adjusted problem\n",
    "y_pred_adjusted = probabilities['prediction']\n",
    "cm = confusion_matrix(y_test, y_pred_adjusted)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No Diabetes', 'Diabetes'], yticklabels=['No Diabetes', 'Diabetes'])\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea27f615-c4f3-4f1b-882e-fcfbb383361a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a6c769-320f-4cea-95e6-c049976295e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
